{
 "metadata": {
  "name": "Lab5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import nltk\nnltk.download()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "showing info http://nltk.github.com/nltk_data/\n"
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": "True"
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "sentence = \"\"\"At eight o'clock on Thursday morning, Arthur didn't feel very good.\"\"\"\ntokens = nltk.word_tokenize(sentence)\ntagged = nltk.pos_tag(tokens)\ntagged",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": "[('At', 'IN'),\n ('eight', 'CD'),\n (\"o'clock\", 'JJ'),\n ('on', 'IN'),\n ('Thursday', 'NNP'),\n ('morning', 'NN'),\n (',', ','),\n ('Arthur', 'NNP'),\n ('did', 'VBD'),\n (\"n't\", 'RB'),\n ('feel', 'VB'),\n ('very', 'RB'),\n ('good', 'JJ'),\n ('.', '.')]"
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "entities = nltk.chunk.ne_chunk(tagged)\nentities",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": "Tree('S', [('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'JJ'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), (',', ','), Tree('PERSON', [('Arthur', 'NNP')]), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')])"
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "entities.draw()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "cd ~/datascience-fall14/lab5",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "/home/terrapin/datascience-fall14/lab5\n"
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "with open(\"news1.html\", \"r\") as myfile:\n    data = myfile.read()   \nsentences = nltk.sent_tokenize(data)\nsentences = [nltk.word_tokenize(sent) for sent in sentences]\nsentences = [nltk.pos_tag(sent) for sent in sentences]\nprint(nltk.ne_chunk(sentences[0]))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "(S\n  CDC/NNP\n  considers/NNS\n  adding/VBG\n  names/NNS\n  of/IN\n  health/NN\n  workers/NNS\n  monitored/VBD\n  for/IN\n  (PERSON Ebola/NNP)\n  to/TO\n  no-fly/NNP\n  list/NN\n  (PERSON Published/NNP)\n  October/NNP\n  16/CD\n  ,/,\n  2014/CD\n  FoxNews.com/JJ\n  </NN\n  http/NN\n  :/:\n  //www.foxnews.com//JJ\n  >/NN\n  (PERSON Facebook/NNP)\n  </NNP\n  #/#\n  >/:\n  558/CD\n  Twitter/NNP\n  </NNP\n  #/#\n  >/:\n  597/CD\n  livefyre/NN\n  </:\n  #/#\n  >/:\n  1623/CD\n  Email/NNP\n  </NNP\n  #/#\n  >/:\n  Print/NNP\n  </:\n  #/#\n  >/:\n  Now/NNP\n  Playing/NNP\n  CDC/NNP\n  :/:\n  Second/NNP\n  (PERSON Dallas/NNP Ebola/NNP)\n  patient/NN\n  took/VBD\n  commercial/JJ\n  flight/NN\n  Never/RB\n  autoplay/NN\n  videos/NNS\n  </:\n  #/#\n  >/:\n  The/DT\n  (ORGANIZATION Centers/NNPS)\n  for/IN\n  (PERSON Disease/NNP Control/NNP)\n  and/CC\n  Prevention/NNP\n  is/VBZ\n  considering/VBG\n  adding/VBG\n  the/DT\n  names/NNS\n  of/IN\n  healthcare/NN\n  workers/NNS\n  being/VBG\n  monitored/VBN\n  for/IN\n  the/DT\n  (ORGANIZATION Ebola/NNP)\n  virus/VBZ\n  to/TO\n  the/DT\n  government/NN\n  's/POS\n  no-fly/JJ\n  list/NN\n  ,/,\n  federal/JJ\n  officials/NNS\n  tell/VBP\n  (PERSON Fox/NNP News/NNP)\n  ./.)\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\nIN = re.compile(r'.*\\bin\\b(?!\\b.+ing)')\nfor doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n    for rel in nltk.sem.extract_rels('ORG', 'LOC', doc, corpus='ieer', pattern = IN):\n        print(nltk.sem.rtuple(rel))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[ORG: u'WHYY'] u'in' [LOC: u'Philadelphia']\n[ORG: u'McGlashan &AMP; Sarrail'] u'firm in' [LOC: u'San Mateo']\n[ORG: u'Freedom Forum'] u'in' [LOC: u'Arlington']\n[ORG: u'Brookings Institution'] u', the research group in' [LOC: u'Washington']"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n[ORG: u'Idealab'] u', a self-described business incubator based in' [LOC: u'Los Angeles']\n[ORG: u'Open Text'] u', based in' [LOC: u'Waterloo']\n[ORG: u'WGBH'] u'in' [LOC: u'Boston']\n[ORG: u'Bastille Opera'] u'in' [LOC: u'Paris']"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n[ORG: u'Omnicom'] u'in' [LOC: u'New York']\n[ORG: u'DDB Needham'] u'in' [LOC: u'New York']\n[ORG: u'Kaplan Thaler Group'] u'in' [LOC: u'New York']\n[ORG: u'BBDO South'] u'in' [LOC: u'Atlanta']\n[ORG: u'Georgia-Pacific'] u'in' [LOC: u'Atlanta']\n"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "with open(\"news1.html\", \"r\") as myfile:\n    data = myfile.read()   \nsentences = nltk.sent_tokenize(data)\nsentences = [nltk.word_tokenize(sent) for sent in sentences]\nsentences = [nltk.pos_tag(sent) for sent in sentences]\n\nfor sentence in sentences:\n    chunks = nltk.ne_chunk(sentence)\n    for chunk in chunks:\n        if type(chunk) is nltk.tree.Tree:\n            for name in chunk.leaves():\n                print name[0] + \", \" + chunk.label()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Ebola, PERSON\nPublished, PERSON\nFacebook, PERSON\nDallas, PERSON\nEbola, PERSON\nCenters, ORGANIZATION\nDisease, PERSON\nControl, PERSON\nEbola, ORGANIZATION\nFox, PERSON\nNews, PERSON\nDallas, PERSON\nVinson, PERSON\nEbola, ORGANIZATION\nThomas, PERSON\nEdward, PERSON\nDuncan, PERSON\nTexas, ORGANIZATION\nHealth, ORGANIZATION\nADVERTISEMENT, ORGANIZATION\nTexas, ORGANIZATION\nVinson, PERSON\nVinson, PERSON\nNina, PERSON\nPham, PERSON\nDuncan, GPE\nCDC, ORGANIZATION\nDuncan, GPE\nCDC, ORGANIZATION"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nVinson, PERSON\nCleveland, GPE\nDallas, GPE\nFrontier, ORGANIZATION\nAirlines, ORGANIZATION\nEbola, ORGANIZATION\nVinson, PERSON\nCDC, ORGANIZATION\nDavid, PERSON\nDaigle, PERSON\nVinson, PERSON\nEbola, PERSON\nCDC, ORGANIZATION\nThomas, PERSON\nFrieden, PERSON\nVinson, PERSON"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nOhio, GPE\nFrieden, PERSON\nDuncan, GPE\nCDC, ORGANIZATION"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nFrontier, GPE\nCleveland, GPE\nDenver, GPE\nCentral, ORGANIZATION"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nTexas, ORGANIZATION\nVinson, PERSON\nFrontier, PERSON\nCDC, ORGANIZATION\nCDC, ORGANIZATION"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nEbola, GPE\nTexas, PERSON"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nHealth, PERSON\nPresbyterian, PERSON\nHospital, PERSON\nFrieden, PERSON\nHouse, ORGANIZATION\nEmergy, ORGANIZATION\nCommerce, ORGANIZATION\nCommittee, ORGANIZATION\nAnthony, PERSON"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nFauci, PERSON\nNational, ORGANIZATION\nInstitute, ORGANIZATION\nAllergy, GPE\nInfectious, ORGANIZATION\nDiseases, ORGANIZATION\nNational, ORGANIZATION\nInstitutes, ORGANIZATION\nHealth, GPE\nDuncan, PERSON\nDallas, GPE\nSpain, GPE\nEbola, PERSON\nMedical, GPE"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nAssociated, ORGANIZATION\nDuncan, PERSON\nVinson, PERSON\nAtlanta, GPE\nEmory, ORGANIZATION\nUniversity, ORGANIZATION\nHospital, ORGANIZATION\nObama, PERSON"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nU.S., GPE\nUnited, GPE\nStates, GPE\nSWAT, ORGANIZATION"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nCDC, ORGANIZATION\nObama, PERSON\nEbola, ORGANIZATION\nEbola, GPE"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nEmory, ORGANIZATION\nUniversity, ORGANIZATION\nHospital, ORGANIZATION\nAtlanta, GPE\nVinson, PERSON\nDavid, PERSON\nLewkowict, PERSON\nAssociated, ORGANIZATION\n"
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "IN = re.compile(r'.*\\bof\\b(?!\\b.+ing)')\nfor doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n    for rel in nltk.sem.extract_rels('ORG', 'PER', doc, corpus='ieer', pattern = IN):\n        print(nltk.sem.rtuple(rel))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[ORG: u'University of Chicago Law Review'] u\"titled ``Cyberspace and the Law of the Horse,''\" [PER: u'Easterbrook']\n"
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "IN = re.compile(r'.*\\bfrom\\b(?!\\b.+ing)')\nfor doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n    for rel in nltk.sem.extract_rels('PER', 'ORG', doc, corpus='ieer', pattern = IN):\n        print(nltk.sem.rtuple(rel))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[PER: u'James Boyle'] u'from' [ORG: u'American University']\n[PER: u'Lawrence'] u'withdrew from active involvement, and financial problems began to impede' [ORG: u'Wells']"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "IN = re.compile(r'.*\\bto\\b(?!\\b.+ing)')\nfor doc in nltk.corpus.ieer.parsed_docs('NYT_19980315'):\n    for rel in nltk.sem.extract_rels('PER', 'ORG', doc, corpus='ieer', pattern = IN):\n        print(nltk.sem.rtuple(rel))",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "[PER: u'Lillian R. Berkman'] u'to support its' [ORG: u'Center for Internet and Society']\n[PER: u'Clinton'] u\"administration's proposal to adapt copyright law to cyberspace, said\" [ORG: u'Berkeley']\n[PER: u'Lawrence'] u'withdrew from active involvement, and financial problems began to impede' [ORG: u'Wells']"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n"
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}